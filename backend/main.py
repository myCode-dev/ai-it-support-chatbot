from fastapi import FastAPI
from pydantic import BaseModel
import openai
import os
import json
import random
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware
from fuzzywuzzy import process

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

app = FastAPI()

# CORS è¨­å®šï¼Œå…è¨±æ‰€æœ‰å‰ç«¯è«‹æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],  
    allow_headers=["*"],  
)

# è¨­å®š OpenAI API Key
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ“‚ **è¼‰å…¥ FAQ JSON**
faq_data = [
    {"question": "How do I reset my password?", "answer": "Go to Settings -> Security -> Reset Password."},
    {"question": "My VPN is not working, what should I do?", "answer": "Restart your computer and try again."},
    {"question": "How do I request a new laptop?", "answer": "Submit an IT request ticket via the IT Support Portal."}
]

# å„²å­˜ä½¿ç”¨è€…å°è©±ç´€éŒ„
user_sessions = {}

# å„²å­˜å ±ä¿®å–®
tickets = []

# ğŸ“Œ **æ¨¡ç³ŠåŒ¹é… FAQ å•é¡Œ**
def check_faq(question):
    questions = [faq["question"] for faq in faq_data]
    best_match, score = process.extractOne(question, questions)
    if score > 70:
        return next(faq["answer"] for faq in faq_data if faq["question"] == best_match)
    return None

# ğŸ¯ **èŠå¤© API**
class ChatRequest(BaseModel):
    user_id: str
    message: str

@app.post("/chat")
async def chat(query: ChatRequest):
    user_id = query.user_id
    question = query.message

    # å»ºç«‹ä½¿ç”¨è€…å°è©±ç´€éŒ„
    if user_id not in user_sessions:
        user_sessions[user_id] = []

    # 1ï¸âƒ£ **å…ˆæŸ¥è©¢ FAQ**
    faq_answer = check_faq(question)
    if faq_answer:
        return {"response": faq_answer, "suggest_ticket": False}

    # 2ï¸âƒ£ **å¦‚æœ FAQ æ²’æœ‰ç­”æ¡ˆï¼Œä½¿ç”¨ OpenAI å›ç­”**
    messages = [{"role": "system", "content": "You are an IT support assistant."}]
    messages += user_sessions[user_id][-5:]  # åªä¿ç•™æœ€è¿‘ 5 å‰‡å°è©±

    messages.append({"role": "user", "content": question})

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages
    )
    
    bot_response = response['choices'][0]['message']['content']

    # å„²å­˜å°è©±
    user_sessions[user_id].append({"role": "user", "content": question})
    user_sessions[user_id].append({"role": "assistant", "content": bot_response})

    # 3ï¸âƒ£ **å¦‚æœ AI å›ç­”ä¸å¤ æ˜ç¢ºï¼Œæä¾›å ±ä¿®å»ºè­°**
    suggest_ticket = "contact IT support" in bot_response.lower() or "unable to help" in bot_response.lower()

    return {"response": bot_response, "suggest_ticket": suggest_ticket}

# ğŸŸï¸ **IT å ±ä¿® API**
class TicketRequest(BaseModel):
    user_id: str
    issue: str

@app.post("/ticket")
async def create_ticket(ticket: TicketRequest):
    ticket_id = random.randint(1000, 9999)
    new_ticket = {
        "ticket_id": ticket_id,
        "user_id": ticket.user_id,
        "issue": ticket.issue,
        "status": "submitted"
    }
    tickets.append(new_ticket)
    return new_ticket

@app.get("/tickets")
async def get_tickets():
    return tickets

# **å•Ÿå‹•æ‡‰ç”¨**
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))  # é è¨­ç‚º 8000
    uvicorn.run(app, host="0.0.0.0", port=port)
